#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIä¿¡æ¯èšåˆå¹³å° - ç³»ç»Ÿæµ‹è¯•è„šæœ¬
éªŒè¯çœŸå®æ•°æ®æ”¶é›†å’Œå‰ç«¯é›†æˆæ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from data_collector import DataCollector

def test_data_collection():
    """æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½...")
    
    async def run_test():
        async with DataCollector() as collector:
            news_items = await collector.collect_all()
            
            if len(news_items) > 0:
                print(f"âœ… æˆåŠŸæ”¶é›†åˆ° {len(news_items)} æ¡æ–°é—»")
                
                # æ˜¾ç¤ºå‰3æ¡æ–°é—»
                for i, news in enumerate(news_items[:3], 1):
                    print(f"  {i}. {news.title}")
                    print(f"     é‡è¦æ€§: {news.importance_score:.1f}")
                    print(f"     æ¥æº: {news.source}")
                    print()
                
                return True
            else:
                print("âŒ æœªæ”¶é›†åˆ°ä»»ä½•æ–°é—»")
                return False
    
    return asyncio.run(run_test())

def test_data_files():
    """æµ‹è¯•æ•°æ®æ–‡ä»¶"""
    print("ğŸ§ª æµ‹è¯•æ•°æ®æ–‡ä»¶...")
    
    # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    data_files = list(Path('.').glob('ai_news_*.json'))
    
    if not data_files:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return False
    
    latest_file = max(data_files, key=lambda f: f.stat().st_mtime)
    print(f"ğŸ“ ä½¿ç”¨æœ€æ–°æ•°æ®æ–‡ä»¶: {latest_file}")
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"âœ… æ•°æ®æ–‡ä»¶æ ¼å¼æ­£ç¡®ï¼ŒåŒ…å« {len(data)} æ¡æ–°é—»")
        
        # éªŒè¯æ•°æ®ç»“æ„
        required_fields = ['id', 'title', 'summary', 'url', 'source', 'importance_score']
        sample_item = data[0] if data else {}
        
        missing_fields = [field for field in required_fields if field not in sample_item]
        if missing_fields:
            print(f"âŒ æ•°æ®ç»“æ„ä¸å®Œæ•´ï¼Œç¼ºå°‘å­—æ®µ: {missing_fields}")
            return False
        
        print("âœ… æ•°æ®ç»“æ„éªŒè¯é€šè¿‡")
        
        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        importance_scores = [item.get('importance_score', 0) for item in data]
        avg_importance = sum(importance_scores) / len(importance_scores)
        high_importance_count = sum(1 for score in importance_scores if score >= 8.0)
        
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"  - å¹³å‡é‡è¦æ€§: {avg_importance:.1f}")
        print(f"  - é«˜é‡è¦æ€§æ–°é—»: {high_importance_count} æ¡")
        
        # æ˜¾ç¤ºæ•°æ®æºåˆ†å¸ƒ
        sources = {}
        for item in data:
            source = item.get('source', 'Unknown')
            sources[source] = sources.get(source, 0) + 1
        
        print(f"ğŸ“¡ æ•°æ®æºåˆ†å¸ƒ:")
        for source, count in sources.items():
            print(f"  - {source}: {count} æ¡")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")
        return False

def test_web_files():
    """æµ‹è¯•Webæ–‡ä»¶"""
    print("ğŸ§ª æµ‹è¯•Webæ–‡ä»¶...")
    
    required_files = [
        'index_realdata.html',
        'js/realDataLoader.js',
        'js/main_realdata.js',
        'styles/realdata.css'
    ]
    
    missing_files = []
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
    
    if missing_files:
        print(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {missing_files}")
        return False
    
    print("âœ… æ‰€æœ‰Webæ–‡ä»¶å­˜åœ¨")
    
    # æ£€æŸ¥HTMLæ–‡ä»¶ä¸­æ˜¯å¦åŒ…å«çœŸå®æ•°æ®ç‰ˆæœ¬çš„å¼•ç”¨
    with open('index_realdata.html', 'r', encoding='utf-8') as f:
        html_content = f.read()
    
    if 'realDataLoader.js' in html_content and 'realdata.css' in html_content:
        print("âœ… HTMLæ–‡ä»¶æ­£ç¡®å¼•ç”¨çœŸå®æ•°æ®ç‰ˆæœ¬")
        return True
    else:
        print("âŒ HTMLæ–‡ä»¶æœªæ­£ç¡®å¼•ç”¨çœŸå®æ•°æ®ç‰ˆæœ¬")
        return False

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…"""
    print("ğŸ§ª æµ‹è¯•ä¾èµ–åŒ…...")
    
    required_packages = ['aiohttp', 'feedparser', 'bs4']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print(f"âŒ ç¼ºå°‘ä¾èµ–åŒ…: {missing_packages}")
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…")
    return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ AIä¿¡æ¯èšåˆå¹³å° - ç³»ç»Ÿæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("ä¾èµ–åŒ…æ£€æŸ¥", test_dependencies),
        ("æ•°æ®æ”¶é›†æµ‹è¯•", test_data_collection),
        ("æ•°æ®æ–‡ä»¶æµ‹è¯•", test_data_files),
        ("Webæ–‡ä»¶æµ‹è¯•", test_web_files)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}")
        print("-" * 30)
        
        try:
            if test_func():
                passed += 1
                print(f"âœ… {test_name} - é€šè¿‡")
            else:
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            print(f"ğŸ’¥ {test_name} - å¼‚å¸¸: {str(e)}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ª")
        print("\nğŸš€ å¯åŠ¨å‘½ä»¤:")
        print("  ./start_realdata.sh")
        print("\nğŸ“± è®¿é—®åœ°å€:")
        print("  å‰ç«¯: http://localhost:8081")
        print("  ç®¡ç†: http://localhost:8082")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯")
        sys.exit(1)

if __name__ == "__main__":
    main()